{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Caffe Model checkpoint!\n",
    "Let's get the stuff converted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from namedlist import namedlist\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import caffe\n",
    "import numpy as np\n",
    "from caffe.proto import caffe_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe_filename = '../checkpoints/mobilenet.caffemodel'\n",
    "\n",
    "caffemodel_params = caffe_pb2.NetParameter()\n",
    "caffemodel_str = open(caffe_filename, 'rb').read()\n",
    "caffemodel_params.ParseFromString(caffemodel_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'data', 'ImageData', 0),\n",
      " (1, 'label_data_1_split', 'Split', 0),\n",
      " (2, 'conv1', 'Convolution', [32, 3, 3, 3]),\n",
      " (3, 'conv1/bn', 'BatchNorm', [32]),\n",
      " (4, 'conv1/scale', 'Scale', [32]),\n",
      " (5, 'relu1', 'ReLU', 0),\n",
      " (6, 'conv2_1/dw', 'Convolution', [32, 1, 3, 3]),\n",
      " (7, 'conv2_1/dw/bn', 'BatchNorm', [32]),\n",
      " (8, 'conv2_1/dw/scale', 'Scale', [32]),\n",
      " (9, 'relu2_1/dw', 'ReLU', 0),\n",
      " (10, 'conv2_1/sep', 'Convolution', [64, 32, 1, 1]),\n",
      " (11, 'conv2_1/sep/bn', 'BatchNorm', [64]),\n",
      " (12, 'conv2_1/sep/scale', 'Scale', [64]),\n",
      " (13, 'relu2_1/sep', 'ReLU', 0),\n",
      " (14, 'conv2_2/dw', 'Convolution', [64, 1, 3, 3]),\n",
      " (15, 'conv2_2/dw/bn', 'BatchNorm', [64]),\n",
      " (16, 'conv2_2/dw/scale', 'Scale', [64]),\n",
      " (17, 'relu2_2/dw', 'ReLU', 0),\n",
      " (18, 'conv2_2/sep', 'Convolution', [128, 64, 1, 1]),\n",
      " (19, 'conv2_2/sep/bn', 'BatchNorm', [128]),\n",
      " (20, 'conv2_2/sep/scale', 'Scale', [128]),\n",
      " (21, 'relu2_2/sep', 'ReLU', 0),\n",
      " (22, 'conv3_1/dw', 'Convolution', [128, 1, 3, 3]),\n",
      " (23, 'conv3_1/dw/bn', 'BatchNorm', [128]),\n",
      " (24, 'conv3_1/dw/scale', 'Scale', [128]),\n",
      " (25, 'relu3_1/dw', 'ReLU', 0),\n",
      " (26, 'conv3_1/sep', 'Convolution', [128, 128, 1, 1]),\n",
      " (27, 'conv3_1/sep/bn', 'BatchNorm', [128]),\n",
      " (28, 'conv3_1/sep/scale', 'Scale', [128]),\n",
      " (29, 'relu3_1/sep', 'ReLU', 0),\n",
      " (30, 'conv3_2/dw', 'Convolution', [128, 1, 3, 3]),\n",
      " (31, 'conv3_2/dw/bn', 'BatchNorm', [128]),\n",
      " (32, 'conv3_2/dw/scale', 'Scale', [128]),\n",
      " (33, 'relu3_2/dw', 'ReLU', 0),\n",
      " (34, 'conv3_2/sep', 'Convolution', [256, 128, 1, 1]),\n",
      " (35, 'conv3_2/sep/bn', 'BatchNorm', [256]),\n",
      " (36, 'conv3_2/sep/scale', 'Scale', [256]),\n",
      " (37, 'relu3_2/sep', 'ReLU', 0),\n",
      " (38, 'conv4_1/dw', 'Convolution', [256, 1, 3, 3]),\n",
      " (39, 'conv4_1/dw/bn', 'BatchNorm', [256]),\n",
      " (40, 'conv4_1/dw/scale', 'Scale', [256]),\n",
      " (41, 'relu4_1/dw', 'ReLU', 0),\n",
      " (42, 'conv4_1/sep', 'Convolution', [256, 256, 1, 1]),\n",
      " (43, 'conv4_1/sep/bn', 'BatchNorm', [256]),\n",
      " (44, 'conv4_1/sep/scale', 'Scale', [256]),\n",
      " (45, 'relu4_1/sep', 'ReLU', 0),\n",
      " (46, 'conv4_2/dw', 'Convolution', [256, 1, 3, 3]),\n",
      " (47, 'conv4_2/dw/bn', 'BatchNorm', [256]),\n",
      " (48, 'conv4_2/dw/scale', 'Scale', [256]),\n",
      " (49, 'relu4_2/dw', 'ReLU', 0),\n",
      " (50, 'conv4_2/sep', 'Convolution', [512, 256, 1, 1]),\n",
      " (51, 'conv4_2/sep/bn', 'BatchNorm', [512]),\n",
      " (52, 'conv4_2/sep/scale', 'Scale', [512]),\n",
      " (53, 'relu4_2/sep', 'ReLU', 0),\n",
      " (54, 'conv5_1/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (55, 'conv5_1/dw/bn', 'BatchNorm', [512]),\n",
      " (56, 'conv5_1/dw/scale', 'Scale', [512]),\n",
      " (57, 'relu5_1/dw', 'ReLU', 0),\n",
      " (58, 'conv5_1/sep', 'Convolution', [512, 512, 1, 1]),\n",
      " (59, 'conv5_1/sep/bn', 'BatchNorm', [512]),\n",
      " (60, 'conv5_1/sep/scale', 'Scale', [512]),\n",
      " (61, 'relu5_1/sep', 'ReLU', 0),\n",
      " (62, 'conv5_2/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (63, 'conv5_2/dw/bn', 'BatchNorm', [512]),\n",
      " (64, 'conv5_2/dw/scale', 'Scale', [512]),\n",
      " (65, 'relu5_2/dw', 'ReLU', 0),\n",
      " (66, 'conv5_2/sep', 'Convolution', [512, 512, 1, 1]),\n",
      " (67, 'conv5_2/sep/bn', 'BatchNorm', [512]),\n",
      " (68, 'conv5_2/sep/scale', 'Scale', [512]),\n",
      " (69, 'relu5_2/sep', 'ReLU', 0),\n",
      " (70, 'conv5_3/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (71, 'conv5_3/dw/bn', 'BatchNorm', [512]),\n",
      " (72, 'conv5_3/dw/scale', 'Scale', [512]),\n",
      " (73, 'relu5_3/dw', 'ReLU', 0),\n",
      " (74, 'conv5_3/sep', 'Convolution', [512, 512, 1, 1]),\n",
      " (75, 'conv5_3/sep/bn', 'BatchNorm', [512]),\n",
      " (76, 'conv5_3/sep/scale', 'Scale', [512]),\n",
      " (77, 'relu5_3/sep', 'ReLU', 0),\n",
      " (78, 'conv5_4/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (79, 'conv5_4/dw/bn', 'BatchNorm', [512]),\n",
      " (80, 'conv5_4/dw/scale', 'Scale', [512]),\n",
      " (81, 'relu5_4/dw', 'ReLU', 0),\n",
      " (82, 'conv5_4/sep', 'Convolution', [512, 512, 1, 1]),\n",
      " (83, 'conv5_4/sep/bn', 'BatchNorm', [512]),\n",
      " (84, 'conv5_4/sep/scale', 'Scale', [512]),\n",
      " (85, 'relu5_4/sep', 'ReLU', 0),\n",
      " (86, 'conv5_5/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (87, 'conv5_5/dw/bn', 'BatchNorm', [512]),\n",
      " (88, 'conv5_5/dw/scale', 'Scale', [512]),\n",
      " (89, 'relu5_5/dw', 'ReLU', 0),\n",
      " (90, 'conv5_5/sep', 'Convolution', [512, 512, 1, 1]),\n",
      " (91, 'conv5_5/sep/bn', 'BatchNorm', [512]),\n",
      " (92, 'conv5_5/sep/scale', 'Scale', [512]),\n",
      " (93, 'relu5_5/sep', 'ReLU', 0),\n",
      " (94, 'conv5_6/dw', 'Convolution', [512, 1, 3, 3]),\n",
      " (95, 'conv5_6/dw/bn', 'BatchNorm', [512]),\n",
      " (96, 'conv5_6/dw/scale', 'Scale', [512]),\n",
      " (97, 'relu5_6/dw', 'ReLU', 0),\n",
      " (98, 'conv5_6/sep', 'Convolution', [1024, 512, 1, 1]),\n",
      " (99, 'conv5_6/sep/bn', 'BatchNorm', [1024]),\n",
      " (100, 'conv5_6/sep/scale', 'Scale', [1024]),\n",
      " (101, 'relu5_6/sep', 'ReLU', 0),\n",
      " (102, 'conv6/dw', 'Convolution', [1024, 1, 3, 3]),\n",
      " (103, 'conv6/dw/bn', 'BatchNorm', [1024]),\n",
      " (104, 'conv6/dw/scale', 'Scale', [1024]),\n",
      " (105, 'relu6/dw', 'ReLU', 0),\n",
      " (106, 'conv6/sep', 'Convolution', [1024, 1024, 1, 1]),\n",
      " (107, 'conv6/sep/bn', 'BatchNorm', [1024]),\n",
      " (108, 'conv6/sep/scale', 'Scale', [1024]),\n",
      " (109, 'relu6/sep', 'ReLU', 0),\n",
      " (110, 'pool6', 'Pooling', 0),\n",
      " (111, 'fc7', 'Convolution', [1000, 1024, 1, 1]),\n",
      " (112, 'fc7_fc7_0_split', 'Split', 0),\n",
      " (113, 'loss', 'SoftmaxWithLoss', 0),\n",
      " (114, 'top1/acc', 'Accuracy', 0),\n",
      " (115, 'top5/acc', 'Accuracy', 0)]\n"
     ]
    }
   ],
   "source": [
    "layers = caffemodel_params.layer\n",
    "names = [(i, l.name, l.type, l.blobs[0].shape.dim if len(l.blobs) else 0) for i, l in enumerate(layers)]\n",
    "pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution\n",
      "[32, 3, 3, 3] 1444\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "layer = layers[idx]\n",
    "print(layer.type)\n",
    "a = np.array(layer.blobs[0].data)\n",
    "s = layer.blobs[0].shape.dim\n",
    "print(s, 38*38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to get it converted...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import mobilenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load caffe model.\n",
    "caffe_filename = '../checkpoints/mobilenet.caffemodel'\n",
    "caffemodel_params = caffe_pb2.NetParameter() \n",
    "caffemodel_params.ParseFromString(open(caffe_filename, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separable_convolution2d() got an unexpected keyword argument 'data_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-270fbaedb5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobilenets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenets_arg_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# TF stuff!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/Development/robik.ai/ImageNet-models/nets/mobilenets.py\u001b[0m in \u001b[0;36mmobilenets\u001b[0;34m(inputs, num_classes, width_multiplier, is_training, dropout_keep_prob, scope)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Then, MobileNet blocks!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/paul/Development/robik.ai/ImageNet-models/nets/mobilenets.py\u001b[0m in \u001b[0;36mmobilenet_block\u001b[0;34m(inputs, num_out_channels, stride, scope)\u001b[0m\n\u001b[1;32m    107\u001b[0m             net = slim.separable_conv2d(inputs, None, kernel_size,\n\u001b[1;32m    108\u001b[0m                                         \u001b[0mdepth_multiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                         scope='conv_dw')\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Pointwise convolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             net = slim.conv2d(inputs, num_out_channels, kernel_size,\n",
      "\u001b[0;32m/home/paul/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: separable_convolution2d() got an unexpected keyword argument 'data_format'"
     ]
    }
   ],
   "source": [
    "# MobileNets TF model\n",
    "imgsize = mobilenets.mobilenets.default_image_size\n",
    "shape = (1, imgsize, imgsize, 3)\n",
    "img_input = tf.placeholder(shape=shape, dtype=tf.float32)\n",
    "# Create model.\n",
    "with slim.arg_scope(mobilenets.mobilenets_arg_scope(data_format='NHWC')):\n",
    "    out = mobilenets.mobilenets(img_input, num_classes=1000, is_training=False)\n",
    "\n",
    "# TF stuff!\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "global_step = slim.create_global_step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffemodel = caffe_scope.CaffeScope()\n",
    "caffemodel.load(FLAGS.caffemodel_path)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "with tf.Graph().as_default():\n",
    "    global_step = slim.create_global_step()\n",
    "    num_classes = int(FLAGS.num_classes)\n",
    "\n",
    "    # Select the network.\n",
    "    ssd_class = nets_factory.get_network(FLAGS.model_name)\n",
    "    ssd_params = ssd_class.default_params._replace(num_classes=num_classes)\n",
    "    ssd_net = ssd_class(ssd_params)\n",
    "    ssd_shape = ssd_net.params.img_shape\n",
    "\n",
    "    # Image placeholder and model.\n",
    "    shape = (1, ssd_shape[0], ssd_shape[1], 3)\n",
    "    img_input = tf.placeholder(shape=shape, dtype=tf.float32)\n",
    "    # Create model.\n",
    "    with slim.arg_scope(ssd_net.arg_scope_caffe(caffemodel)):\n",
    "        ssd_net.net(img_input, is_training=False)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as session:\n",
    "        # Run the init operation.\n",
    "        session.run(init_op)\n",
    "\n",
    "        # Save model in checkpoint.\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt_path = FLAGS.caffemodel_path.replace('.caffemodel', '.ckpt')\n",
    "        saver.save(session, ckpt_path, write_meta_graph=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
